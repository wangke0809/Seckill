user  root staff;
worker_processes 2;
#worker_cpu_affinity 01 10;
#error_log  logs/error.log;

pid        logs/nginx.pid;

# 并发相关参数
worker_rlimit_nofile 32767; # 每个进程打开的最大的文件数，受限于操作系统 /etc/security/limits.conf
events {
    multi_accept on;  # 可以一次建立多个连接
    worker_connections  32767;  # 单个工作进程最大并发连接数（似乎与/etc/security/limits.h有关）
    use epoll; # select poll epoll
}

http {
    include       mime.types;
    default_type  application/octet-stream;
    server_tokens off; # 隐藏版本号（防止nginx具体版本号泄露，然后对应nginx版本的bug被利用，攻击）

    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    #limit_req_zone  $remote_addr zone=zone1:160m rate=200r/s;
    #limit_conn_zone $remote_addr zone=zone2:160m;
    access_log  /usr/local/nginx/logs/access.log  main;
    #access_log off;
    # 默认写日志：打开文件写入关闭，max：缓存的文件描述符数量，inactive缓存时间，valid：检查时间间隔，min_uses:在inactive时间段内使用了多少次加入缓存
    # open_file_cache max=200 inactive=20s valid=1m min_uses=2;
    open_file_cache max=200000 inactive=20s;
    open_file_cache_valid 30s;
    open_file_cache_min_uses 2;
    open_file_cache_errors on;

    sendfile        on;
    tcp_nopush     on;
    tcp_nodelay on;

    client_body_buffer_size 10K;
    client_header_buffer_size 1k;
    client_max_body_size 8m;
    large_client_header_buffers 4 4k;

    # 长连接（这是ie浏览器跟nginx之间长连接的配置）
    keepalive_timeout 60s; #长连接的超时时间
    keepalive_requests 2000; #100个请求之后就关闭连接，可以调大
    keepalive_disable msie6; #ie6禁用

    # 压缩相关选项
    gzip on;
    gzip_disable "MSIE [1-6]\.(?!.*SV1)";
    gzip_proxied any;
    gzip_types text/plain application/x-javascript application/javascript text/css application/xml
    gzip_vary on; # Vary: Accept-Encoding
    gzip_min_length 100;
    gzip_static on; # 如果有压缩好的，直接使用

    # 超时时间
    proxy_connect_timeout 5; # 连接proxy超时
    proxy_send_timeout 5;    # proxy连接nginx超时
    proxy_read_timeout 60;   # proxy响应超时

    #开启缓存，2级目录
    #缓存最大有20g，缓存一天，200mb的cache_one,缓存目录是一个两级目录。把文件渲染完以文件的形式存到目录（如果是这样，那跟抢购无关了）
    proxy_cache_path /usr/local/webserver/nginx/proxy_cache levels=1:2 keys_zone=cache_one:200m inactive=1d max_size=20g;
    proxy_ignore_headers X-Accel-Expires Expires Cache-Control;
    proxy_hide_header Cache-Control;
    proxy_hide_header Pragma;

    #反向代理服务器集群(还不知道哪两台服务器用来提供服务器服务)
    upstream server_pool {
        server 10.108.18.79:8080 weight=9 max_fails=2 fail_timeout=30s;
        server 10.108.18.80:8080 weight=9 max_fails=2 fail_timeout=30s;
        server 10.108.18.78:8080 weight=1 max_fails=2 fail_timeout=30s;
        # server 10.108.18.77:8080 weight=1 max_fails=2 fail_timeout=30s;
        keepalive 1000; # 最大的空闲的长连接数（如果感觉不够，调大就可以了）
    }

    limit_conn zone2 5; #limit_conn就是一个IP限制了10个连接
    limit_rate 500k; #limit_rate就是限制一个连接的带宽
    limit_conn_status 403;

    server {
        listen       80;
        server_name  localhost;

        #charset koi8-r;

        #if ($http_x_forwarded_for = "") {
        #    return 403;
        #}

        location / {
            #漏桶数burst为5，brust的意思就是，如果第1,2,3,4秒请求为19个，第5秒的请求为25个是被允许的。但是如果你第1秒就25个请求，第2秒超过20的请求返回503错误。nodelay，如果不设置该选项，第1秒25个请求时，5个请求放到第2秒执行，设置nodelay，25个请求将在第1秒执行。
            #limit_req zone=zone1 burst=20 nodelay;
            #limit_req_status 403;
            #limit_conn zone2 5; #limit_conn就是一个IP限制了10个连接
            #limit_rate 500k; #limit_rate就是限制一个连接的带宽
            #limit_conn_status 403;
            aio threads;
            # 如果在upstream server_pool的keepalive配置数字，那么就需要配置这些proxy
            proxy_http_version 1.1;
            # 下面这两个跟http2.0相关
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
           # Tomcat获取真实用户ip
            proxy_set_header Host $http_host;
            #proxy_set_header X-Real-IP $remote_addr;
            #proxy_set_header X-Forwarded-For $remote_addr;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_pass http://server_pool;
        }

        # 静态文件加缓存（本次抢购就不需要了）

        #crapy等爬虫工具的抓取
        #if ($http_user_agent ~* "Scrapy|Sogou web spider|Baiduspider") {
        #    return 403;
        #}
        #禁止指定UA及UA为空的访问
        #if ($http_user_agent ~ "Ezooms|^$" )
        #{
        #    return 403;
        #}
        #禁止非GET|HEAD|POST方式的抓取
        #if ($request_method !~ ^(GET|POST)$) {
        #    return 403;
        #}
        # 状态监控（在linux上wget一下那个网址就好了）
        location /nginx_status {
            stub_status on;
            access_log off;
            allow 127.0.0.1;
            #allow 192.168.220.139;
            deny all;
        }


        #error_page  404              /404.html;

        # redirect server error pages to the static page /50x.html
        #
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   html;
        }

        # proxy the PHP scripts to Apache listening on 127.0.0.1:80
        #
        #location ~ \.php$ {
        #    proxy_pass   http://127.0.0.1;
        #}

        # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000
        #
        #location ~ \.php$ {
        #    root           html;
        #    fastcgi_pass   127.0.0.1:9000;
        #    fastcgi_index  index.php;
        #    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;
        #    include        fastcgi_params;
        #}

        # deny access to .htaccess files, if Apache's document root
        # concurs with nginx's one
        #
        #location ~ /\.ht {
        #    deny  all;
        #}
    }


    # another virtual host using mix of IP-, name-, and port-based configuration
    #
    #server {
    #    listen       8000;
    #    listen       somename:8080;
    #    server_name  somename  alias  another.alias;

    #    location / {
    #        root   html;
    #        index  index.html index.htm;
    #    }
    #}


    # HTTPS server
    #
    #server {
    #    listen       443 ssl;
    #    server_name  localhost;

    #    ssl_certificate      cert.pem;
    #    ssl_certificate_key  cert.key;

    #    ssl_session_cache    shared:SSL:1m;
    #    ssl_session_timeout  5m;

    #    ssl_ciphers  HIGH:!aNULL:!MD5;
    #    ssl_prefer_server_ciphers  on;

    #    location / {
    #        root   html;
    #        index  index.html index.htm;
    #    }
    #}

}